# -*- coding: utf-8 -*-
"""Mapreduce_Harshit Raj Taneja.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cXSsvjWmfthzT5OyKytm-UFZQiITFdYM

Birth Date 12 January 2001

File Extraction
"""

from google.colab import files
uploaded = files.upload()

!pip install PyPDF2

from PyPDF2 import PdfReader

pdf_path = "harrypotter.pdf"      # DOB-12/01/2001(12 JANUARY 2001)

reader = PdfReader(pdf_path)

text = ""

# Extract pages 12–22
for page_num in range(11, 22):
    text += reader.pages[page_num].extract_text()

with open("file1.txt", "w", encoding="utf-8") as f:
    f.write(text)

print("Pages 12–22 extracted successfully!")

files.download("file1.txt")

from PyPDF2 import PdfReader

pdf_path = "harrypotter.pdf"       # DOB-12/01/2001(12 JANUARY 2001)

reader = PdfReader(pdf_path)

text = ""

# Extract pages 101–110
for page_num in range(100, 110):
    text += reader.pages[page_num].extract_text()

with open("file2.txt", "w", encoding="utf-8") as f:
    f.write(text)

print("Pages 101–110 extracted successfully into file2.txt!")

files.download("file2.txt")

"""Q1 Count Occurences of Each Word"""

import re
from collections import defaultdict

# MAPPING FUNCTION        # DOB-12/01/2001(12 JANUARY 2001)
def mapper(text):
    words = re.findall(r"\b[a-zA-Z']+\b", text.lower())
    for word in words:
        yield (word, 1)

# REDUCING FUNCTION
def reducer(mapped_data):
    grouped = defaultdict(list)

    # Shuffle phase
    for word, count in mapped_data:
        grouped[word].append(count)

    # Reduce phase
    reduced = {}
    for word, counts in grouped.items():
        reduced[word] = sum(counts)

    return reduced


#  EXECUTION
with open("file1.txt", "r", encoding="utf-8") as f:
    text = f.read()

mapped = list(mapper(text))
word_counts = reducer(mapped)

# Sort by frequency (descending)
sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

# Saving to output file
with open("output_file1.txt", "w", encoding="utf-8") as out:
    for word, count in sorted_words:
        out.write(f"{word}\t{count}\n")

print("output_file1.txt created successfully!")
# Displaying words in output
for word, count in sorted_words:
    print(f"{word}\t{count}")

!pip install pyspellchecker

"""Q2 Count Non-English Words"""

import re
from collections import defaultdict
from spellchecker import SpellChecker

spell = SpellChecker()

# MAPPING FUNCTION   # DOB-12/01/2001(12 JANUARY 2001)
def mapper(text):
    words = re.findall(r"\b[a-zA-Z']+\b", text.lower())
    for word in words:
        yield (word, 1)

#  REDUCING FUNCTION
def reducer(mapped_data):
    grouped = defaultdict(list)

    for word, count in mapped_data:
        grouped[word].append(count)

    reduced = {}
    for word, counts in grouped.items():
        reduced[word] = sum(counts)

    return reduced


#  EXECUTION
with open("file2.txt", "r", encoding="utf-8") as f:
    text = f.read()

mapped = list(mapper(text))
word_counts = reducer(mapped)

# Identifying non-English words
non_english_words = {}

for word, count in word_counts.items():
    if word not in spell:
        non_english_words[word] = count

# Sorted results
sorted_non_english = sorted(non_english_words.items(), key=lambda x: x[1], reverse=True)

# Saving to output file
with open("output_file2.txt", "w", encoding="utf-8") as out:
    for word, count in sorted_non_english:
        out.write(f"{word}\t{count}\n")

print("output_file2.txt created successfully!")

for word, count in sorted_non_english:
    print(f"{word}\t{count}")

"""Github Link : https://github.com/harryx12/DATA603_Assignments_HarshitRajTaneja"""

